version: "3.8"

services:
  triton:
    image: nvcr.io/nvidia/tritonserver:25.03-py3
    container_name: triton
    restart: unless-stopped
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./weights:/mnt/weights
    command: "/bin/bash -c 'tritonserver \
      --model-repository=/mnt/weights/models \
      --model-control-mode=poll \
      --repository-poll-secs=300 \
      --disable-auto-complete-config \
      --allow-http=true \
      --allow-grpc=true \
      --allow-metrics=true \
      --log-verbose=1'"
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"

